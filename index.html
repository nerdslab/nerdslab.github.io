<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>NerDS Lab</title>
  <link rel="stylesheet" href="style.css">
  <style>
    main {
      max-width: 800px;
      margin: 0 auto;
      padding: 1em;
    }
    figure {
      margin-top: 2em;
      text-align: center;
    }
    figure img {
      max-width: 100%;
      border-radius: 10px;
    }
    figure figcaption {
      font-style: italic;
      color: #555;
      margin-top: 0.5em;
    }
    .bottom-image {
      display: block;
      margin: 2em auto;
      width: 300px;
      border-radius: 8px;
    }
  </style>
</head>
<body>
  <header>
    <img src="images/logo_outline.png" alt="NerDS Lab Logo" height="80">
    <h1>NerDS Lab</h1>
    <nav>
      <a href="index.html">Home</a> |
      <a href="about.html">About</a> |
      <a href="people.html">People</a> |
      <a href="publications.html">Publications</a> |
      <a href="contact.html">Contact</a>
    </nav>
  </header>

<main>
  <h2>Welcome to the NerDS Lab</h2>
  <p>The Neural Data Science (NerDS) Lab builds machine learning methods that help us understand the brain, behavior, and other complex biological systems. We combine neuroscience, AI, and data-driven modeling to uncover representations of neural computation and to build tools for scientific discovery.</p>

<section id="news" style="margin-top: 3em;">
  <h3>📰 News & Publications</h3>
  <ul style="list-style-type: none; padding-left: 0;">

    <li><strong>Jan 2025:</strong> 🧠 <a href="https://arxiv.org/abs/2504.08201" style="color: #008b8b;">Neural Encoding and Decoding at Scale</a> accepted at <strong>[ICML 2025]</strong></li>

    <li><strong>Jan 2025:</strong> 🌍 <a href="https://openreview.net/pdf?id=8C8LJIqF4y" style="color: #008b8b;">Time Series Domain Adaptation via Channel-Selective Representation Alignment</a> published in <strong>[TMLR]</strong></li>

    <li><strong>Jan 2025:</strong> 🧬 <a href="https://openreview.net/pdf?id=IuU0wcO0mo" style="color: #008b8b;">Multi-session, multi-task neural decoding from distinct cell-types and brain regions</a> accepted at <strong>[ICLR 2025]</strong></li>

    <li><strong>Jan 2025:</strong> 🔍 <a href="https://www.biorxiv.org/content/10.1101/2024.11.05.622159.abstract" style="color: #008b8b;">In vivo cell-type and brain region classification via multimodal contrastive learning</a> accepted at <strong>[ICLR 2025]</strong></li>

    <li><strong>Dec 2024:</strong> ⚖️ <a href="https://arxiv.org/pdf/2502.20141" style="color: #008b8b;">Your contrastive learning problem is secretly a distribution alignment problem</a> accepted at <strong>[NeurIPS 2024]</strong></li>

  </ul>

  <figure style="text-align: center; margin-top: 2em;">
    <img src="images/IMG_2521.jpg" alt="Lab update" style="width: 300px; border-radius: 8px;">
    <figcaption>🎓 Celebrating recent papers and progress at the NerDS Lab!</figcaption>
  </figure>
</section>

</main>

  
  <figure>
    <img src="images/mainpage.jpg" alt="Visualization of neural decoding and representation learning" style="width: 300px; border-radius: 8px;">
    <figcaption>Mapping the brain with machine learning: decoding activity, learning structure, and understanding function.</figcaption>
  </figure>

  <footer>
    <p>© 2025 NerDS Lab</p>
  </footer>
</body>
</html>
