<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>NerDS Lab</title>
  <link rel="stylesheet" href="style.css">
  <style>
    main {
      max-width: 800px;
      margin: 0 auto;
      padding: 1em;
    }
    figure {
      margin-top: 2em;
      text-align: center;
    }
    figure img {
      max-width: 100%;
      border-radius: 10px;
    }
    figure figcaption {
      font-style: italic;
      color: #555;
      margin-top: 0.5em;
    }
    .bottom-image {
      display: block;
      margin: 2em auto;
      width: 300px;
      border-radius: 8px;
    }
  </style>
</head>
<body>
  <header>
    <img src="images/logo_outline.png" alt="NerDS Lab Logo" height="80">
    <h1>NerDS Lab</h1>
    <nav>
      <a href="index.html">Home</a> |
      <a href="about.html">About</a> |
      <a href="people.html">People</a> |
      <a href="publications.html">Publications</a> |
      <a href="contact.html">Contact</a>
    </nav>
  </header>

<main>
  <h2>Welcome to the NerDS Lab</h2>
  <p>The Neural Data Science (NerDS) Lab at UPenn, led by Dr. Eva Dyer, builds machine learning methods that help us understand the brain, behavior, and other complex biological systems. We combine neuroscience, AI, and data-driven modeling to uncover representations of neural computation and to build tools for scientific discovery.</p>

<section id="news" style="margin-top: 3em;">
  <h3>📰 News & Publications</h3>
  <ul style="list-style-type: none; padding-left: 0;">

    <li><strong>Jan 2025:</strong> 🧠 <a href="https://arxiv.org/abs/2504.08201" style="color: #008b8b;">Neural Encoding and Decoding at Scale</a> accepted at <strong>[ICML 2025]</strong></li>

    <li><strong>Jan 2025:</strong> 🌍 <a href="https://openreview.net/pdf?id=8C8LJIqF4y" style="color: #008b8b;">Time Series Domain Adaptation via Channel-Selective Representation Alignment</a> published in <strong>[TMLR]</strong></li>

    <li><strong>Jan 2025:</strong> 🧬 <a href="https://openreview.net/pdf?id=IuU0wcO0mo" style="color: #008b8b;">Multi-session, multi-task neural decoding from distinct cell-types and brain regions</a> accepted at <strong>[ICLR 2025]</strong></li>

    <li><strong>Jan 2025:</strong> 🔍 <a href="https://www.biorxiv.org/content/10.1101/2024.11.05.622159.abstract" style="color: #008b8b;">In vivo cell-type and brain region classification via multimodal contrastive learning</a> accepted at <strong>[ICLR 2025]</strong></li>

    <li><strong>Dec 2024:</strong> ⚖️ <a href="https://arxiv.org/pdf/2502.20141" style="color: #008b8b;">Your contrastive learning problem is secretly a distribution alignment problem</a> accepted at <strong>[NeurIPS 2024]</strong></li>

    <li><strong>Dec 2024:</strong> 🧠 <a href="https://arxiv.org/abs/2407.14668" style="color: #008b8b;">Towards a “universal translator” for neural dynamics at single-cell, single-spike resolution</a> accepted at <strong>[NeurIPS 2024]</strong></li>

    <li><strong>Sept 2024:</strong> 🧬 <a href="https://arxiv.org/abs/2308.06578" style="color: #008b8b;">The time is ripe to reverse engineer an entire nervous system</a> — simulating behavior from neural interactions on <strong>arXiv</strong></li>

    <li><strong>Nov 2024:</strong> 🧠 <a href="https://elifesciences.org/reviewed-preprints/101506" style="color: #008b8b;">A conserved code for anatomy</a> published in <strong>[eLife]</strong></li>

    <li><strong>July 2024:</strong> 📊 <a href="https://arxiv.org/abs/2402.11742" style="color: #008b8b;">Balanced data, imbalanced spectra</a> accepted at <strong>[ICML 2024]</strong></li>

    <li><strong>July 2024:</strong> 🧠 <a href="https://www.nature.com/articles/s41593-024-01715-2" style="color: #008b8b;">A non-oscillatory, millisecond-scale embedding of brain state</a> published in <strong>[Nature Neuroscience]</strong></li>

    <li><strong>June 2024:</strong> ⏱️ <a href="https://openreview.net/forum?id=c56TWtYp0W" style="color: #008b8b;">GAFormer: Enhancing time-series transformers</a> accepted at <strong>[ICLR 2024]</strong></li>

    <li><strong>April 2024:</strong> 🧩 <a href="https://arxiv.org/pdf/2210.05021.pdf" style="color: #008b8b;">The good, the bad and the ugly sides of data augmentation</a> now in <strong>[JMLR]</strong></li>

    <li><strong>Jan 2024:</strong> 🛠️ <a href="https://arxiv.org/abs/2308.14596" style="color: #008b8b;">LatentDR</a> accepted at <strong>[WACV 2024]</strong></li>

  </ul>

  <figure style="text-align: center; margin-top: 2em;">
    <img src="images/IMG_2521.jpg" alt="Lab update" style="width: 300px; border-radius: 8px;">
    <figcaption>🎓 Celebrating recent papers and progress at the NerDS Lab!</figcaption>
  </figure>
</section>

</main>

  
  <figure>
    <img src="images/mainpage.jpg" alt="Visualization of neural decoding and representation learning">
    <figcaption>Mapping the brain with machine learning: decoding activity, learning structure, and understanding function.</figcaption>
  </figure>

  <footer>
    <p>© 2025 NerDS Lab</p>
  </footer>
</body>
</html>
