<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>About ‚Äì NerDS Lab</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&family=Major+Mono+Display&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css">
  <style>
    body {
      margin: 0;
      font-family: 'Inter', sans-serif;
      line-height: 1.6;
      color: #222;
      background-color: #fff;
    }

    header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      padding: 1em 2em;
      background: #fff;
      border-bottom: 1px solid #ddd;
      flex-wrap: wrap;
    }

    .logo-title {
      display: flex;
      align-items: center;
    }

    .logo-title img {
      height: 60px;
      margin-right: 15px;
    }

    .logo-title h1 {
      margin: 0;
      font-family: 'Major Mono Display', monospace;
      font-size: 48px;
      font-weight: 400;
      text-transform: none;
      color: #222;
    }

    nav {
      display: flex;
      gap: 6px;
      flex-wrap: wrap;
      margin-top: 10px;
    }

    nav a {
      text-decoration: none;
      color: #333;
      font-weight: 500;
      font-size: 0.95em;
      padding: 0 6px;
    }

    nav a:hover {
      color: #007acc;
    }

    main {
      max-width: 1000px;
      margin: 0 auto;
      padding: 3em 2em;
    }

    h2 {
      font-size: 1.8em;
      margin-top: 0;
      margin-bottom: 0.5em;
      border-bottom: 2px solid #ddd;
      padding-bottom: 5px;
    }

    h3 {
      margin-top: 2em;
    }

    .research-area-table {
      width: 100%;
      margin-bottom: 2em;
      border-collapse: collapse;
    }

    .research-area-table td {
      vertical-align: top;
      padding: 10px;
    }

    .research-image {
      width: 200px;
      border-radius: 8px;
    }

    .feature-pubs {
      margin-top: 10px;
    }

    .funding-grid {
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));
      gap: 20px;
      justify-items: center;
      align-items: center;
      margin-top: 1em;
    }

    .funding-grid img {
      max-width: 150px;
      height: auto;
    }

    .centered-img {
      width: 600px;
      display: block;
      margin: 2em auto;
      border-radius: 8px;
    }

    footer {
      text-align: center;
      margin-top: 4em;
      padding: 2em;
      background: #f5f5f5;
      font-size: 0.9em;
    }

    footer a {
      color: #0066cc;
      text-decoration: none;
    }

    @media (max-width: 768px) {
      header {
        flex-direction: column;
        align-items: flex-start;
      }

      nav {
        justify-content: center;
        width: 100%;
        margin-top: 1em;
      }
    }
  </style>
</head>
<body>

<header>
  <div class="logo-title">
    <img src="images/logo_outline.png" alt="nerds lab logo">
    <h1>nerds_lab</h1>
  </div>
  <nav>
    <a href="index.html">Home</a>
    <a href="about.html">About</a>
    <a href="people.html">People</a>
    <a href="publications.html">Publications</a>
    <a href="nerdslabcode.html">Code</a>
    <a href="contact.html">Contact</a>
  </nav>
</header>

<main>
  <h2>About the NerDS Lab</h2>

  <p>The <strong>Neural Data Science (NerDS) Lab</strong> develops data-centric machine learning methods to understand complex biological systems. Our interdisciplinary research integrates neuroscience, AI, and representation learning to decode neural computation, interpret behavior, and uncover general principles of biological intelligence.</p>

  <!-- Insert any image if desired -->
  <!-- <img src="images/about_image.jpg" alt="NerDS Lab Vision" class="centered-img"> -->

  <table class="research-area-table">
    <tr>
      <td><img class="research-image" src="images/20250523_1818_Neural Network Brainscape_simple_compose_01jvzkjmsqe4ha7x3sbrkcd800.png" alt="Latent space of brain activity"></td>
      <td>
        <h3>üß† Understanding the Brain Through AI</h3>
        <p>We create scalable models that decode brain activity across tasks, cell types, and animals. Our foundation models for neuroscience support transfer across sessions and contexts.</p>
        <div class="feature-pubs">
          <strong>Featured Papers:</strong>
          <ul>
            <li><a href="https://arxiv.org/pdf/2310.16046" target="_blank">A unified, scalable framework for neural population decoding (NeurIPS 2023)</a></li>
            <li><a href="https://openreview.net/pdf?id=IuU0wcO0mo" target="_blank">Multi-session, multi-task neural decoding (ICLR 2025)</a></li>
          </ul>
        </div>
      </td>
    </tr>
  </table>

  <table class="research-area-table">
    <tr>
      <td><img class="research-image" src="images/AugmentedCat.png" alt="Behavior embeddings"></td>
      <td>
        <h3>üîÅ Self-Supervised and Contrastive Learning</h3>
        <p>We apply self-supervised methods to reveal hidden patterns in neural and behavioral data. Our models learn structured representations without labels, discovering multiscale behavior and neural motifs.</p>
        <div class="feature-pubs">
          <strong>Featured Papers:</strong>
          <ul>
            <li><a href="https://arxiv.org/abs/2303.08811" target="_blank">Relax, it doesn‚Äôt matter how you get there (NeurIPS 2023)</a></li>
            <li><a href="https://arxiv.org/pdf/2111.02338" target="_blank">Drop, Swap, and Generate (NeurIPS 2021, Oral)</a></li>
          </ul>
        </div>
      </td>
    </tr>
  </table>

  <table class="research-area-table">
    <tr>
      <td><img class="research-image" src="images/20250523_2016_Abstract Manifold Art_simple_compose_01jvztaye3e4ytz8tvbzvjnq9x.png" alt="Domain adaptation visualization"></td>
      <td>
        <h3>üåç Domain Adaptation and Representation Alignment</h3>
        <p>We design representation alignment methods that adapt across devices and conditions in time series data. Our channel-selective and Sinkhorn-based techniques improve model robustness and transfer.</p>
        <div class="feature-pubs">
          <strong>Featured Papers:</strong>
          <ul>
            <li><a href="https://openreview.net/pdf?id=8C8LJIqF4y" target="_blank">Channel-Selective Representation Alignment (TMLR 2025)</a></li>
            <li><a href="https://proceedings.mlr.press/v139/lin21a.html" target="_blank">Moving data through anchor points (ICML 2021)</a></li>
          </ul>
        </div>
      </td>
    </tr>
  </table>

  <table class="research-area-table">
    <tr>
      <td><img class="research-image" src="images/20250523_1959_Futuristic Neuron Network_simple_compose_01jvzsbj4cesms0r6r6jfrb0w4.png" alt="Cell type classification"></td>
      <td>
        <h3>üß¨ Mapping Cell Types from Activity</h3>
        <p>We build classifiers that use only neural activity to predict cell types and brain regions. Our contrastive approaches generalize across mice and modalities, bridging function and transcriptomics.</p>
        <div class="feature-pubs">
          <strong>Featured Papers:</strong>
          <ul>
            <li><a href="https://www.biorxiv.org/content/10.1101/2024.11.05.622159.abstract" target="_blank">Multimodal contrastive learning (ICLR 2025)</a></li>
            <li><a href="https://www.cell.com/cell-reports/pdfExtended/S2211-1247(23)00329-7" target="_blank">Transcriptomic cell type structures (Cell Reports 2023)</a></li>
          </ul>
        </div>
      </td>
    </tr>
  </table>

  <table class="research-area-table">
    <tr>
      <td><img class="research-image" src="images/20250523_2009_Graph Nodes Connections_simple_compose_01jvzsxrbzencb72dakj4tgrw6.png" alt="Graph upsampling illustration"></td>
      <td>
        <h3>üìä Graph Learning</h3>
        <p>Our lab advances graph neural network methods to model diverse graph datasets. We develop transformers and graph augmentation techniques for scalable and transferable graph learning.</p>
        <div class="feature-pubs">
          <strong>Featured Papers:</strong>
          <ul>
            <li><a href="http://proceedings.mlr.press/v202/azabou23a/azabou23a.pdf" target="_blank">Half-Hop (ICML 2023)</a></li>
            <li><a href="https://arxiv.org/abs/2407.11907" target="_blank">GraphFM (arXiv 2024)</a></li>
          </ul>
        </div>
      </td>
    </tr>
  </table>

  <section id="funding" style="padding: 2em 0;">
    <h2>Funding</h2>
    <p>We are fortunate to receive funding from the following sources:</p>
    <div class="funding-grid">
      <img src="images/funding/nihlogo.png" alt="NIH" />
      <img src="images/funding/NSF_Logo.jpg" alt="NSF" />
      <img src="images/funding/cifarlogo.jpg" alt="CIF
