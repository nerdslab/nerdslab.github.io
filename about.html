<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>People - NerDS Lab</title>
  <link rel="stylesheet" href="style.css">
  <style>
    .person { display: flex; align-items: flex-start; margin: 20px 0; }
    .person img { width: 100px; margin-right: 20px; border-radius: 8px; }
    .person-info { max-width: 800px; }
    h2 { border-bottom: 2px solid #ddd; padding-bottom: 5px; }
  </style>
</head>
<body>
<header>
  <img src="images/logo.png" alt="NerDS Lab Logo" height="80">
  <h1>NerDS Lab</h1>
  <nav>
    <a href="index.html">Home</a> |
    <a href="about.html">About</a> |
    <a href="people.html">People</a> |
    <a href="publications.html">Publications</a> |
    <a href="contact.html">Contact</a>
  </nav>
</header>
<main>

<section id="about" style="padding: 2em 0;">
  <div class="container">
    <h2>About the NerDS Lab</h2>
    <p>The <strong>Neural Data Science (NerDS) Lab</strong>, led by <strong>Dr. Eva Dyer</strong> at Georgia Tech, develops data-centric machine learning methods to understand complex biological systems. Our interdisciplinary research integrates neuroscience, AI, and representation learning to decode neural computation, interpret behavior, and uncover general principles of biological intelligence.</p>

    <div class="research-area">
      <h3>üß† Understanding the Brain Through AI</h3>
      <img src="img/brain_latent_space.png" alt="Latent space of brain activity" style="max-width: 100%; height: auto;">
      <p>We create scalable models that decode brain activity across tasks, cell types, and animals. Our foundation models for neuroscience support transfer across sessions and contexts.</p>
      <p><strong>Featured Paper:</strong> <a href="https://openreview.net/pdf?id=IuU0wcO0mo" style="color: #008b8b;">Multi-session, multi-task neural decoding from distinct cell-types and brain regions (ICLR 2025)</a></p>
    </div>

    <div class="research-area">
      <h3>üîÅ Self-Supervised and Contrastive Learning</h3>
      <img src="img/behavior_embeddings.png" alt="Behavior embeddings" style="max-width: 100%; height: auto;">
      <p>We apply self-supervised methods to reveal hidden patterns in neural and behavioral data. Our models learn structured representations without labels, discovering multiscale behavior and neural motifs.</p>
      <p><strong>Featured Paper:</strong> <a href="https://arxiv.org/abs/2303.08811" style="color: #008b8b;">Relax, it doesn‚Äôt matter how you get there (NeurIPS 2023)</a></p>
    </div>

    <div class="research-area">
      <h3>üåç Domain Adaptation and Representation Alignment</h3>
      <img src="img/domain_alignment.png" alt="Domain adaptation visualization" style="max-width: 100%; height: auto;">
      <p>We design representation alignment methods that adapt across devices and conditions in time series data. Our channel-selective and Sinkhorn-based techniques improve model robustness and transfer.</p>
      <p><strong>Featured Paper:</strong> <a href="https://openreview.net/pdf?id=8C8LJIqF4y" style="color: #008b8b;">Time Series Domain Adaptation via Channel-Selective Representation Alignment (TMLR 2025)</a></p>
    </div>

    <div class="research-area">
      <h3>üß¨ Mapping Cell Types from Activity</h3>
      <img src="img/celltype_classification.png" alt="Cell type classification" style="max-width: 100%; height: auto;">
      <p>We build classifiers that use only neural activity to predict cell types and brain regions. Our contrastive approaches generalize across mice and modalities, bridging function and transcriptomics.</p>
      <p><strong>Featured Paper:</strong> <a href="https://www.biorxiv.org/content/10.1101/2024.11.05.622159.abstract" style="color: #008b8b;">In vivo cell-type and brain region classification via multimodal contrastive learning (ICLR 2025)</a></p>
    </div>

    <div class="research-area">
      <h3>üìä Graph Learning for Scientific Data</h3>
      <img src="img/graph_upsampling.png" alt="Graph upsampling illustration" style="max-width: 100%; height: auto;">
      <p>Our lab advances graph neural network methods to model scientific data. We develop transformers and upsampling techniques for scalable and transferable graph learning.</p>
      <p><strong>Featured Paper:</strong> <a href="http://proceedings.mlr.press/v202/azabou23a/azabou23a.pdf" style="color: #008b8b;">Half-Hop: A graph upsampling approach for slowing down message passing (ICML 2023)</a></p>
    </div>
  </div>
</section>

